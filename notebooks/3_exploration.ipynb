{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "\n",
    "Questions to ask: \n",
    "\n",
    "1. How do values distribute for the main variable *search_interest*?\n",
    "1. What are keywords with high search interest? \n",
    "2. What is the average search interest ...\n",
    "    1. for a keyword?\n",
    "    1. for a keyword that has at least 1 entry > 0?\n",
    "    1. for a keyword that has at least 1 entry > 50?\n",
    "    1. for a keyword that has at least 1 entry == 100?\n",
    "3. How is search interest ...\n",
    "    1. correlated with positive or negative ESG classification?\n",
    "    1. correlated and distributed across industries?\n",
    "    1. correlated and distributed across ESG classificatoin (positive/negative)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD FILES\n",
      "----------------------------------------\n",
      "processed/missing_search_interest/part-00000-7907bd4a-f8a5-412d-b638-4c9efcc6be19-c000.csv\n",
      "processed/search_interest/part-00000-a119d364-b63e-47a0-b874-5e7771e8bbe8-c000.csv\n",
      "processed/search_interest_meta/part-00000-3a16f3f1-266e-4037-98c4-e8837529daf3-c000.csv\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import s3fs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import helper_functions.py\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../src/data')\n",
    "import helper_functions as h\n",
    "\n",
    "# set configuration\n",
    "conf = {'region_name': 'us-west-2', \n",
    "        'bucket_name': 'esg-analytics', \n",
    "        'input_prefix': 'raw/', \n",
    "        'output_prefix': 'processed/',\n",
    "        'select_files': ['20201017-191627gtrends_preprocessed.csv', \n",
    "                         '20201017-191627gtrends_metadata.csv'], \n",
    "       'export_files':['search_interest', \n",
    "                       'search_interest_meta',\n",
    "                      'missing_search_interest']}\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('esg-analytics')\n",
    "\n",
    "# load files with .csv format from output_prefix\n",
    "load_files= []\n",
    "for obj in bucket.objects.filter(Prefix=conf['output_prefix']): \n",
    "    if obj.key.split('.')[-1] == 'csv':\n",
    "        load_files.append(obj.key)\n",
    "\n",
    "print('LOAD FILES\\n'+'-'*40, *load_files, sep='\\n')\n",
    "\n",
    "df_missing = pd.read_csv(f\"s3://{conf['bucket_name']}/{load_files[0]}\")#, names=['keyword'])\n",
    "df = pd.read_csv(f\"s3://{conf['bucket_name']}/{load_files[1]}\")#, names=['date', 'keyword', 'search_interest'])\n",
    "df_meta = pd.read_csv(f\"s3://{conf['bucket_name']}/{load_files[2]}\") #, names=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality checks (with Great Expectations) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "\n",
    "# load df into ge\n",
    "ge_df = ge.from_pandas(df)\n",
    "ge_meta = ge.from_pandas(df_meta)\n",
    "ge_missing = ge.from_pandas(df_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"meta\": {},\n",
       "  \"success\": false,\n",
       "  \"result\": {\n",
       "    \"element_count\": 998325,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 252,\n",
       "    \"unexpected_percent\": 0.025242280820374125,\n",
       "    \"unexpected_percent_nonmissing\": 0.025242280820374125,\n",
       "    \"partial_unexpected_list\": [\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100,\n",
       "      100\n",
       "    ]\n",
       "  },\n",
       "  \"exception_info\": null\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ge_df.expect_table_columns_to_match_ordered_list(['date', 'keyword', 'search_interest'])\n",
    "ge_df.expect_column_values_to_be_between('search_interest', min_value=0, max_value=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"meta\": {\n",
       "    \"great_expectations_version\": \"0.12.9\"\n",
       "  },\n",
       "  \"data_asset_type\": \"Dataset\",\n",
       "  \"expectations\": [\n",
       "    {\n",
       "      \"meta\": {},\n",
       "      \"expectation_type\": \"expect_table_columns_to_match_ordered_list\",\n",
       "      \"kwargs\": {\n",
       "        \"column_list\": [\n",
       "          \"date\",\n",
       "          \"keyword\",\n",
       "          \"search_interest\"\n",
       "        ]\n",
       "      }\n",
       "    },\n",
       "    {\n",
       "      \"meta\": {},\n",
       "      \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"search_interest\",\n",
       "        \"min_value\": 0,\n",
       "        \"max_value\": 99\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"expectation_suite_name\": \"default\"\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ge_df.get_expectation_suite(discard_failed_expectations=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge of the API query and its metadata\n",
    "\n",
    "Each row in `metadata` (*df_meta*) contains a keyword. In contrast, each row in `gtrends` (*df*) contains search interest per week for a keyword which repeats across dates. Thus, we have to populate `metadata` as many times as there are unique dates for each keyword which is $261$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_query_meta(df_query, df_meta, id_col):\n",
    "    \"\"\"Left join of df_query on df_meta, where df_meta is the input to the query\n",
    "    \n",
    "    :param df_query: pandas DataFrame with query results\n",
    "    :param df_meta: pandas DataFrame with input data for query\n",
    "    :param id_col: string that specifies the identifying column common to both dataframes\n",
    "    :return : DataFrame of joined datasets\n",
    "    \"\"\"\n",
    "    # take id as index for both\n",
    "    df_query_idcol = df_query.set_index(id_col)\n",
    "    df_meta_idcol = df_meta.set_index(id_col)\n",
    "    \n",
    "    # join query and meta\n",
    "    df_joined = df_query_idcol.join(df_meta_idcol, on=id_col, how='left').reset_index()\n",
    "    \n",
    "    return df_joined\n",
    "\n",
    "df_all = join_query_meta(df_query=df, df_meta=df_meta, id_col='keyword')\n",
    "\n",
    "h.make_csv(df_all, 'merged_gtrends_meta.csv', '../data/processed', header=True)\n",
    "\n",
    "# check correct storage\n",
    "df = pd.read_csv('../data/processed/merged_gtrends_meta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of search_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.displot(df.search_interest)\n",
    "ax = g.axes.flatten()[0]\n",
    "ax.set_title('Search interest')\n",
    "ax.set_xlabel('Search interest across all dates')\n",
    "plt.show()\n",
    "\n",
    "g = sns.displot(df.search_interest[df.search_interest > 0])\n",
    "ax = g.axes.flatten()[0]\n",
    "ax.set_title('Search interest > 0')\n",
    "ax.set_xlabel('Search interest across all dates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_search_interest = df.search_interest.mean()\n",
    "median_search_interest = df.search_interest.median()\n",
    "\n",
    "print(\"Search interest\")\n",
    "print('-'*40)\n",
    "print(f'Average: {avg_search_interest} \\nMedian: {median_search_interest}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords and firms with highest search interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "highest average per keyword "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "print(f\"{top_n} highest average search interest per keyword:\\n\",\\\n",
    "      df.groupby(\"keyword\").mean().search_interest.sort_values(ascending=False)[:top_n]\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most searched firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{top_n} highest average search interest per firm:\\n\",\\\n",
    "      df.groupby('firm_name_processed').search_interest.mean().sort_values(ascending=False)[:top_n]\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search interest == 100 across whole timespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"How often search interest reached maximum across the whole timespan:\\n\"\n",
    "    ,df[df.search_interest == 100].keyword.value_counts()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What has been search most recently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_recent = df.date.tail().values\n",
    "print(\"Recent average search activity\\n\", '-'*40)\n",
    "\n",
    "print(\"What keywords have been searched recently from {} to {}:\".format(date_recent[0], date_recent[-1]))\n",
    "\n",
    "print(df[df.date.isin(date_recent)]\\\n",
    "    .groupby('keyword')\\\n",
    "    .search_interest\\\n",
    "    .mean()\\\n",
    "    .sort_values(ascending=False)[:top_n])\n",
    "\n",
    "print('-'*40)\n",
    "\n",
    "print(\"Which firms have been searched recently from {} to {}:\".format(date_recent[0], date_recent[-1]))\n",
    "print(df[df.date.isin(date_recent)]\\\n",
    "    .groupby('firm_name_processed')\\\n",
    "    .search_interest\\\n",
    "    .mean()\\\n",
    "    .sort_values(ascending=False)[:top_n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"correlation between search interest and ESG classification (positive=1/negative=0)\")\n",
    "print(round(df.corr().loc['search_interest','positive'], 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
